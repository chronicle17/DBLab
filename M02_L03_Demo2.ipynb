{"cells":[{"cell_type":"markdown","source":["# DEMO: Mounting Azure Blob Storage and Azure Data Lake Store\n---\nThis demo will show you how to *mount* two of the most popular big data stores on Azure: Azure Blob Storage and Azure Data Lake Store.  \n  \n*Mounting* Storage in Databricks refers to the process of establishing a connection between your Azure Databricks workspace and other Azure Storage Services. Mounting them allows them to be accessible via tools like `dbutils`. Additionally, and more importantly, it makes interacting with data stores on Azure simpler."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a2d8f01b-7ff3-49f0-8c72-a6bfbb686eff"}}},{"cell_type":"markdown","source":["First, let's take a look at Mounting Azure Blob Storage.  \n  \nHowever, we need a Azure Blob Storage instance before we continue (if you haven't provisioned Azure Blob Storage, do so now):\n  \nWithin the Azure Portal you need to grab two pieces of information:\n1. The Endpoint for the blob with the format of 'wasbs://[your-container-name]@[your-storage-account-name].blob.core.windows.net'\n2. The value associated with one of the Access Keys"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"269a6b85-ef5a-45f6-83bb-82115ea2806a"}}},{"cell_type":"code","source":["# Name of the Storage Account\nblobAccountName = \"<ENTER YOUR STORAGE ACCOUNT NAME>\"\n\n# Name of the Container in the Blob Storage Account\ncontainerName = \"<ENTER IN THE NAME OF THE CONTAINER>\"\n\n# the second piece of information described above goes into blobKey\nblobKey = \"<ENTER IN THE STORAGE ACCOUNT ACCESS KEY>\"\n\n# the first piece of information described above goes into blobEndpoint\nblobEndpoint = \"wasbs://{0}@{1}.blob.core.windows.net/\".format(containerName, blobAccountName)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a742050e-fd02-43f0-9f84-ae38b97f2e28"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Below is a command to mount the Azure Blob Storage container within your Databricks workspace.  \n**Source**: The endpoint for your blob  \n**mount_point**: The filepath that you will use to access and interact with the mounted storage within Azure Databricks  \n**extra_configs**: Here, the only extra configuration you need is the Access Key value"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0301450e-cffb-4749-b97d-04b9d6948b3b"}}},{"cell_type":"markdown","source":["## Explanation of extra_configs and How it should be constructed\nIn extra_configs, Databricks needs the key-value pair of \"fs.azure.account.key.STORAGE-ACCOUNT-NAME-HERE.blob.core.windows.net\" : blobKey  \n  \nThe access key (i.e. the variable blobKey) should have already been provided in the above cell  \n  \nThe config \"fs.azure.account.key.STORAGE-ACCOUNT-NAME-HERE.blob.core.windows.net\" is telling Databricks what kind of credential you are using for authenticating the connection to the storage account  \n  \nTo fill this out you need to supply the Storage Account Name. For example, if you deployed a Storage Account with the name of **workshopStorage** then your configuration would look like fs.azure.account.key.**workshopStorage**.blob.core.windows.net  \n  \nThe full `extra_configs` would look like the following: `extra_configs = {\"fs.azure.account.key.workshopStorage.blob.core.windows.net\":blobKey}`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14edcd18-38d2-4823-b513-78363f48efa4"}}},{"cell_type":"code","source":["configKey = \"fs.azure.account.key.{0}.blob.core.windows.net\".format(blobAccountName)\n\ndbutils.fs.mount(\n  source = blobEndpoint,\n  mount_point = \"/mnt/blobmount\",\n  extra_configs = {configKey:blobKey})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"17469aa0-6939-4c78-a6ca-2902bdbde4ce"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now lets take a look and make sure it is all connected."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"be9082cc-8b6f-453d-bb0b-f5f03449ef86"}}},{"cell_type":"code","source":["dbutils.fs.ls(\"/mnt/blobmount\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0d0dc065-99ab-4e0a-9c37-afd60327c9a3"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["As you can see there is a directory, albiet an empty one. Nonetheless, this proves the mounting was successful and that files placed in this location in your Azure Blob Storage instance can be accessed here in Azure Databricks."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b8af75e6-ee6c-4d4f-a390-c8ab64a71266"}}},{"cell_type":"markdown","source":["Now let's take a look at mounting Azure Data Lake Store. We will be using Azure Data Lake Store Gen1 for this demo. Documentation for mounting Azure Data Lake Store Gen2 can be found within the documentation for Azure Databricks (https://docs.microsoft.com/en-us/azure/databricks/data/data-sources/azure/adls-gen2/)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7a6fa2d-cf90-4575-8c8e-a8a8f3c70f08"}}},{"cell_type":"markdown","source":["**Required before proceeding**  \n- Azure Data Lake Store gen2 Instance deployed into your Azure environment\n- A folder called 'main' created at the root of the Azure Data Lake Store gen 2\n- App registered with Azure Active Directory (https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-create-service-principal-portal)\n- Make sure we are setting correct ACL level permission using the service principal object ID. NOT the app Object ID \n  - Navigate to azure portal and select \"Azure Active Directory\" on the left pane. Then select \"App Registrations\". Find your registered app, which was set up in the step\n    above. Record the \"Application (Client) ID\". \n  - Now open up your Azure CLI (must be preinstalled). Run the command \"az ad sp show --id (Application (Client) ID)\"\n  - In the returned results, you will see a field called \"Object ID\". Record the value. \n  - Now open storage explorer (must be installed). Navigate to your adls gen 2 account and expand the hierarchy until you get to your container name. \n  - Right click the container name and select \"Manage Access\". A new window will pop up. Input the Object ID we recorded earlier into the \"Add user or Group\" field.\n  - Select \"Add\" and \"Save\". You will now be ready to complete the rest of the demo.\n\n\n(https://deep.data.blog/2019/03/28/avoiding-error-403-request-not-authorized-when-accessing-adls-gen-2-from-azure-databricks-while-using-a-service-principal/)\n\n\nNow, once this has been set up we can get started with mounting Azure Data Lake Store gen2 in your Databricks workspace. First let's define some needed information for the mounting.  \n  \n**Note**: As you will see there is a little more involved when it comes to mounting Azure Data Lake Store gen2 due to how access and permissions work."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b020bf4c-34b8-4d2b-8649-4bd9ad2b0f8c"}}},{"cell_type":"code","source":["configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n           \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n           \"fs.azure.account.oauth2.client.id\": \"<Application ID>\", #Application ID found on the information blade of the App within App Registrations in Azure Active Directory\n           \"fs.azure.account.oauth2.client.secret\": \"<key>\", # This is the key value that is only shown once, if you did not write it down create a new key and put the value here\n           \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/<Directory ID>/oauth2/token\"} # This is found under Azure Active Directory > Properties - Directory ID (bottom part of the blade)\n\n# Optionally, you can add <your-directory-name> to the source URI of your mount point.\ndbutils.fs.mount(\n  source = \"abfss://<filesystem name>@<storage account name>.dfs.core.windows.net/\",\n  mount_point = \"/mnt/adlsgen2\",\n  extra_configs = configs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"59202942-e872-49a8-8ca0-1efd04fd2e95"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's make sure it is connected!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"10b5ed29-3fae-4937-a835-f142485cf89c"}}},{"cell_type":"code","source":["dbutils.fs.ls(\"/mnt/adlsgen2/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e8bb29f0-5e19-47b9-8dd3-3f006cc5e7bd"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Another useful feature is the `refreshMounts` command that is accessible via the `dbutils` commands. This refreshes the connection between your Databricks workspace and the storage locations on Azure. It is a good way of ensuring that you are still connected to the mounts."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"539525b0-7f0d-4a8d-afc1-532f068e4a25"}}},{"cell_type":"code","source":["dbutils.fs.refreshMounts()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6efbe5f-a5ab-4440-af6f-2325d73e40cb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Before we finish with this demo, let's take a look at how to *unmount* storage locations from your Databricks workspace."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb4a73e5-23e3-4e7f-9295-501a91afa427"}}},{"cell_type":"code","source":["dbutils.fs.unmount(\"/mnt/adlsgen2\")\ndbutils.fs.unmount(\"/mnt/blobmount\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f01444bb-350a-4c51-b623-2589be4d84af"}},"outputs":[],"execution_count":0}],"metadata":{"name":"Mounting Blob Storage and Azure Data Lake Store","notebookId":3792655459449008,"application/vnd.databricks.v1+notebook":{"notebookName":"M02_L03_Demo2","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3826082595091007}},"nbformat":4,"nbformat_minor":0}
